{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n\n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-15T11:52:32.751186Z","iopub.execute_input":"2021-12-15T11:52:32.752064Z","iopub.status.idle":"2021-12-15T11:52:32.779312Z","shell.execute_reply.started":"2021-12-15T11:52:32.751938Z","shell.execute_reply":"2021-12-15T11:52:32.778595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nimport os\nimport cv2\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom skimage.util import random_noise\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:52:32.781196Z","iopub.execute_input":"2021-12-15T11:52:32.781658Z","iopub.status.idle":"2021-12-15T11:52:37.788155Z","shell.execute_reply.started":"2021-12-15T11:52:32.781621Z","shell.execute_reply":"2021-12-15T11:52:37.787414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/stanford-cars-dataset/cars_train/cars_train/'\nfilenames = list(glob.glob(path + '/*.jpg'))\nprint(filenames[:8])                 ","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:52:37.789397Z","iopub.execute_input":"2021-12-15T11:52:37.789638Z","iopub.status.idle":"2021-12-15T11:52:38.261437Z","shell.execute_reply.started":"2021-12-15T11:52:37.789606Z","shell.execute_reply":"2021-12-15T11:52:38.260662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test case for images:","metadata":{}},{"cell_type":"code","source":"for i in range(9):\n    plt.subplot(3, 3, i+1)\n    image = cv2.imread(filenames[i])\n    plt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:52:38.263257Z","iopub.execute_input":"2021-12-15T11:52:38.263451Z","iopub.status.idle":"2021-12-15T11:52:39.548147Z","shell.execute_reply.started":"2021-12-15T11:52:38.263426Z","shell.execute_reply":"2021-12-15T11:52:39.54745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img, val_img, _, _ = train_test_split(filenames, filenames, test_size = 0.2, shuffle = True, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:52:39.549151Z","iopub.execute_input":"2021-12-15T11:52:39.549394Z","iopub.status.idle":"2021-12-15T11:52:39.564122Z","shell.execute_reply.started":"2021-12-15T11:52:39.549359Z","shell.execute_reply":"2021-12-15T11:52:39.563401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Size of training set is: {len(train_img)}', end='\\n----------------------------\\n')\nprint(f'Size of validation set is: {len(val_img)}', end='\\n----------------------------\\n')\nprint(f'Total: {len(train_img) + len(val_img)}')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:52:39.565469Z","iopub.execute_input":"2021-12-15T11:52:39.565719Z","iopub.status.idle":"2021-12-15T11:52:39.571457Z","shell.execute_reply.started":"2021-12-15T11:52:39.565686Z","shell.execute_reply":"2021-12-15T11:52:39.570535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WIDTH = 256\nHEIGHT = 256\nn_channels = 3\nBATCH_SIZE = 64","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:52:39.573025Z","iopub.execute_input":"2021-12-15T11:52:39.573503Z","iopub.status.idle":"2021-12-15T11:52:39.580591Z","shell.execute_reply.started":"2021-12-15T11:52:39.573465Z","shell.execute_reply":"2021-12-15T11:52:39.579804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class  DataGenerator(tf.keras.utils.Sequence):\n    \n    def __init__(self, orig_filenames, batch_size = BATCH_SIZE, shuffle = True):\n        self.orig_filenames = orig_filenames\n        self.noisy_filenames = orig_filenames\n        self.filenames = list(zip(self.orig_filenames, self.noisy_filenames))\n        self.batch_size = BATCH_SIZE\n        self.shuffle = shuffle\n    \n    def __len__(self):\n        return (len(self.orig_filenames) // self.batch_size)\n    \n    def __getitem__(self, idx):\n        batch = self.filenames[idx * self.batch_size : (idx + 1) * self.batch_size]\n        X, Y = self.__data_generation(batch)\n\n        return X, Y\n    \n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.orig_filenames))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n            \n    def __data_generation(self, batch):\n        orig = []\n        noisy = []\n        \n        for orig_file, _ in batch:\n          # image = self.colored_image_loader(orig_file)\n          image = cv2.imread(orig_file) / 255\n#           image = tf.image.convert_image_dtype(image, tf.float32) / 255\n          image = cv2.resize(image, (WIDTH, HEIGHT))\n#           image = tf.image.convert_image_dtype(image, tf.float32)\n            \n          # noisy = cv2.imread(mask_file)\n          # mask = cv2.resize(mask, (WIDTH, HEIGHT))[:, :, 2]\n\n#           orig.append(cv2.resize(image, (252, 252)))\n          orig.append(image)\n          \n          noisy.append(self.make_noisy(image))\n          \n        return  np.array(noisy), np.array(orig)\n\n    # def colored_image_loader(self, image_filename):\n    #   img = cv2.imread(image_filename)\n    #   img = cv2.resize(img, (WIDTH, HEIGHT))\n    #   img = tf.image.convert_image_dtype(img, tf.float32)\n      \n      # return img\n\n    def make_noisy(self, image):\n      # image = cv2.imread(img_file)\n      image_ = image\n      noisy_image = random_noise(image_, mode = 'gaussian')\n      \n      return noisy_image","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:52:39.581831Z","iopub.execute_input":"2021-12-15T11:52:39.582254Z","iopub.status.idle":"2021-12-15T11:52:40.435791Z","shell.execute_reply.started":"2021-12-15T11:52:39.58221Z","shell.execute_reply":"2021-12-15T11:52:40.435036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing the Data Generator:","metadata":{}},{"cell_type":"code","source":"# data = train_X\ndata = DataGenerator(train_img, 64, True)\nx, y = data[0]\n# print(type(x))\n# print(data[0].shape)\nplt.imshow(x[31])\n# plt.imshow(y[31])\n# print(type(X))\n# plt.imshow(X[1][2])\n# print(X)\n# print(train_X[:9])","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:52:40.439317Z","iopub.execute_input":"2021-12-15T11:52:40.439882Z","iopub.status.idle":"2021-12-15T11:52:42.456706Z","shell.execute_reply.started":"2021-12-15T11:52:40.43984Z","shell.execute_reply":"2021-12-15T11:52:42.456047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class  DataGenerator(tf.keras.utils.Sequence):\n    \n#     def __init__(self, orig_filenames, batch_size = BATCH_SIZE, shuffle = True):\n\ntrain_generator = DataGenerator(train_img, BATCH_SIZE)\nval_generator = DataGenerator(val_img, BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:52:42.459064Z","iopub.execute_input":"2021-12-15T11:52:42.459749Z","iopub.status.idle":"2021-12-15T11:52:42.466885Z","shell.execute_reply.started":"2021-12-15T11:52:42.459709Z","shell.execute_reply":"2021-12-15T11:52:42.465954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Model\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Input, Conv2D, UpSampling2D, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:52:42.468373Z","iopub.execute_input":"2021-12-15T11:52:42.468631Z","iopub.status.idle":"2021-12-15T11:52:42.481147Z","shell.execute_reply.started":"2021-12-15T11:52:42.468596Z","shell.execute_reply":"2021-12-15T11:52:42.480467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def create_model():\n#   x = Input(shape=(WIDTH, HEIGHT, n_channels)) \n\n#   # Encoder\n#   e_conv1 = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n#   pool1 = MaxPooling2D((2, 2), padding='same')(e_conv1)\n#   batchnorm_1 = BatchNormalization()(pool1)\n#   e_conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(batchnorm_1)\n#   pool2 = MaxPooling2D((2, 2), padding='same')(e_conv2)\n#   batchnorm_2 = BatchNormalization()(pool2)\n#   e_conv3 = Conv2D(64, (3, 3), activation='relu', padding='same')(batchnorm_2)\n#   h = MaxPooling2D((2, 2), padding='same')(e_conv3)\n\n\n#   # Decoder\n#   d_conv1 = Conv2D(256, (3, 3), activation='relu', padding='same')(h)\n#   up1 = UpSampling2D((2, 2))(d_conv1)\n#   d_conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(up1)\n#   up2 = UpSampling2D((2, 2))(d_conv2)\n#   d_conv3 = Conv2D(64, (3, 3), activation='relu')(up2)\n#   up3 = UpSampling2D((2, 2))(d_conv3)\n#   r = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(up3)\n\n#   model = Model(x, r)\n# #  model.compile(optimizer='adam', loss='mse', metrics = [''])\n#   return model","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:52:42.482421Z","iopub.execute_input":"2021-12-15T11:52:42.482731Z","iopub.status.idle":"2021-12-15T11:52:42.489541Z","shell.execute_reply.started":"2021-12-15T11:52:42.482697Z","shell.execute_reply":"2021-12-15T11:52:42.488803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow.keras.layers as tkl\ndef conv_block(inputs = None, n_filters = 32, kernel_size = 3, batch_norm = True):\n    \n    '''First layer'''\n    \n    conv = tkl.Conv2D(filters = n_filters,\n                      kernel_size = kernel_size,\n                      padding = 'same',\n                      kernel_initializer = 'he_normal')(inputs)\n    \n    if batch_norm:\n        conv = tkl.BatchNormalization()(conv)\n    \n    conv = tkl.Activation('relu')(conv)\n    \n    '''Second layer'''\n    \n    conv = tkl.Conv2D(filters = n_filters,\n                     kernel_size = kernel_size,\n                     padding = 'same',\n                     kernel_initializer = 'he_normal')(conv)\n    \n    if batch_norm:\n        conv = tkl.BatchNormalization()(conv)\n    \n    conv = tkl.Activation('relu')(conv)\n        \n    return conv\n\n\ndef conv_transpose_block(n_filters, kernel_size = 3):\n    conv_transpose = tkl.Conv2DTranspose(n_filters, kernel_size = kernel_size, strides = (2,2), padding = 'same')\n    \n    return conv_transpose\n    \n\ndef u_net(n_filters = 32, dropout_prob = 0.1, batch_norm = True):\n    input_size = (WIDTH, HEIGHT, n_channels)\n    \n    input_img = tf.keras.Input(input_size, name = 'image' )\n    \n    c1 = conv_block(input_img, n_filters, kernel_size = 3)\n    p1 = tkl.MaxPooling2D((2,2))(c1)\n    p1 = tkl.Dropout(dropout_prob)(p1)\n    \n    c2 = conv_block(p1, n_filters * 2, kernel_size = 3)\n    p2 = tkl.MaxPooling2D((2,2))(c2)\n    p2 = tkl.Dropout(dropout_prob)(p2)\n    \n    c3 = conv_block(p2, n_filters * 4, kernel_size = 3)\n    p3 = tkl.MaxPooling2D((2,2))(c3)\n    p3 = tkl.Dropout(dropout_prob)(p3)\n    \n    c4 = conv_block(p3, n_filters * 8, kernel_size = 3)\n    p4 = tkl.MaxPooling2D((2,2))(c4)\n    p4 = tkl.Dropout(dropout_prob)(p4)\n    \n    c5 = conv_block(p4, n_filters * 16 , kernel_size = 3)\n    \n    ''' UpSampling '''\n    \n    u6 = conv_transpose_block(n_filters * 8, kernel_size = 3)(c5)  #----> 256\n    u6 = tkl.concatenate([u6, c4])     #----> 512\n    u6 = tkl.Dropout(dropout_prob)(u6)\n    c6 = conv_block(u6, n_filters * 8, kernel_size = 3)   #----> 256\n    \n    u7 = conv_transpose_block(n_filters * 4)(c6)   #----> 128\n    u7 = tkl.concatenate([u7, c3])   #----> 256\n    u7 = tkl.Dropout(dropout_prob)(u7)\n    c7 = conv_block(u7, n_filters * 4, kernel_size = 3)   #----> 128\n    \n    u8 = conv_transpose_block(n_filters * 2, kernel_size = 3)(c7)   #----> 64\n    u8 = tkl.concatenate([u8, c2])   #----> 128\n    u8 = tkl.Dropout(dropout_prob)(u8)\n    c8 = conv_block(u8, n_filters * 2, kernel_size = 3)   #----> 64\n    \n    u9 = conv_transpose_block(n_filters, kernel_size = 3)(c8)   #----> 32\n    u9 = tkl.concatenate([u9, c1])   #----> 64\n    u9 = tkl.Dropout(dropout_prob)(u9)\n    c9 = conv_block(u9, n_filters , kernel_size = 3)   #----> 32\n    \n    output = tkl.Conv2D(3, (1,1), activation = 'sigmoid')(c9)\n    \n    model = tf.keras.Model(inputs = [input_img], outputs = [output])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:52:42.490964Z","iopub.execute_input":"2021-12-15T11:52:42.491333Z","iopub.status.idle":"2021-12-15T11:52:42.512287Z","shell.execute_reply.started":"2021-12-15T11:52:42.491297Z","shell.execute_reply":"2021-12-15T11:52:42.51131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = create_model()\nmodel = u_net()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:52:42.513462Z","iopub.execute_input":"2021-12-15T11:52:42.5138Z","iopub.status.idle":"2021-12-15T11:52:45.447207Z","shell.execute_reply.started":"2021-12-15T11:52:42.513761Z","shell.execute_reply":"2021-12-15T11:52:45.446428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'mse', metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:52:45.448505Z","iopub.execute_input":"2021-12-15T11:52:45.448762Z","iopub.status.idle":"2021-12-15T11:52:45.463834Z","shell.execute_reply.started":"2021-12-15T11:52:45.448722Z","shell.execute_reply":"2021-12-15T11:52:45.463125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gaussian_early_stop = EarlyStopping(monitor='loss', patience=3)\n# x, y = train_generator\nhistory = model.fit(train_generator,\n                              validation_data = val_generator,\n                              use_multiprocessing = True,\n                              workers = 6, epochs=50)\n# , callbacks=[gaussian_early_stop]\n\n# history = model.fit(train_generator, epochs=50)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T11:52:45.465156Z","iopub.execute_input":"2021-12-15T11:52:45.465551Z","iopub.status.idle":"2021-12-15T15:23:29.971833Z","shell.execute_reply.started":"2021-12-15T11:52:45.465486Z","shell.execute_reply":"2021-12-15T15:23:29.965102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('UnetDenoising.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T15:29:20.52072Z","iopub.execute_input":"2021-12-15T15:29:20.521028Z","iopub.status.idle":"2021-12-15T15:29:20.971418Z","shell.execute_reply.started":"2021-12-15T15:29:20.520975Z","shell.execute_reply":"2021-12-15T15:29:20.970496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate the model: ","metadata":{}},{"cell_type":"code","source":"path = '/kaggle/input/stanford-cars-dataset/cars_test/cars_test/'\ntest_data = list(glob.glob(path + '*.jpg'))\n# print(len(test_data))\n\nevaluation_set = test_data[:64]\ntest_img_path = test_data[104]\ntest_img = cv2.imread(test_img_path)\ntest_img = cv2.resize(test_img, (WIDTH, HEIGHT)) / 255\ntest_img = random_noise(test_img, mode = 'gaussian')\nplt.imshow(test_img)\nprint(test_img.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:19:45.593575Z","iopub.execute_input":"2021-12-15T16:19:45.594341Z","iopub.status.idle":"2021-12-15T16:19:45.863649Z","shell.execute_reply.started":"2021-12-15T16:19:45.594302Z","shell.execute_reply":"2021-12-15T16:19:45.862945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict(test_img)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T15:56:31.399813Z","iopub.execute_input":"2021-12-15T15:56:31.400096Z","iopub.status.idle":"2021-12-15T15:56:31.625092Z","shell.execute_reply.started":"2021-12-15T15:56:31.400063Z","shell.execute_reply":"2021-12-15T15:56:31.623803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_set = []\nfor i in range(64):\n    img = cv2.imread(evaluation_set[i])\n    img = cv2.resize(img, (WIDTH, HEIGHT)) / 255\n    img = random_noise(img, mode = 'gaussian')\n    eval_set.append(img)\neval_set = np.array(eval_set)\n\n# test_generator = DataGenerator(evaluation_set)\n# x, y = test_generator[2]\npredicted = model.predict(eval_set)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:31:58.642074Z","iopub.execute_input":"2021-12-15T16:31:58.642563Z","iopub.status.idle":"2021-12-15T16:31:59.914619Z","shell.execute_reply.started":"2021-12-15T16:31:58.642521Z","shell.execute_reply":"2021-12-15T16:31:59.91383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:21:15.346765Z","iopub.execute_input":"2021-12-15T16:21:15.347061Z","iopub.status.idle":"2021-12-15T16:21:15.351483Z","shell.execute_reply.started":"2021-12-15T16:21:15.347027Z","shell.execute_reply":"2021-12-15T16:21:15.350756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:32:10.260656Z","iopub.execute_input":"2021-12-15T16:32:10.260934Z","iopub.status.idle":"2021-12-15T16:32:10.265821Z","shell.execute_reply.started":"2021-12-15T16:32:10.260904Z","shell.execute_reply":"2021-12-15T16:32:10.265134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.imshow(predicted[10])\npredicted_ = cv2.resize(predicted[11], (500, 500))\n# fig, ax = plt.subplots(1,3)\nprepared_img = cv2.imread(evaluation_set[11]) / 255\nprepared_img = cv2.resize(prepared_img, (500, 500))\nnoisy_orig = random_noise(prepared_img, mode = 'gaussian')\n# ax[0].imshow(prepared_img)\n# ax[1].imshow(predicted_)\n# ax[2].imshow(noisy_orig)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:46:25.978161Z","iopub.execute_input":"2021-12-15T16:46:25.97873Z","iopub.status.idle":"2021-12-15T16:46:26.635675Z","shell.execute_reply.started":"2021-12-15T16:46:25.978689Z","shell.execute_reply":"2021-12-15T16:46:26.634891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(cv2.imread(evaluation_set[10]))","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:31:01.233956Z","iopub.execute_input":"2021-12-15T16:31:01.234804Z","iopub.status.idle":"2021-12-15T16:31:01.485922Z","shell.execute_reply.started":"2021-12-15T16:31:01.234754Z","shell.execute_reply":"2021-12-15T16:31:01.485175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(prepared_img)\nplt.title('original image')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:48:37.371873Z","iopub.execute_input":"2021-12-15T16:48:37.372452Z","iopub.status.idle":"2021-12-15T16:48:37.643618Z","shell.execute_reply.started":"2021-12-15T16:48:37.372411Z","shell.execute_reply":"2021-12-15T16:48:37.642936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(predicted_)\nplt.title('predicted image')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:49:12.010578Z","iopub.execute_input":"2021-12-15T16:49:12.010865Z","iopub.status.idle":"2021-12-15T16:49:12.276582Z","shell.execute_reply.started":"2021-12-15T16:49:12.010834Z","shell.execute_reply":"2021-12-15T16:49:12.275853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(noisy_orig)\nplt.title('noisy image')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:49:08.161557Z","iopub.execute_input":"2021-12-15T16:49:08.161856Z","iopub.status.idle":"2021-12-15T16:49:08.421163Z","shell.execute_reply.started":"2021-12-15T16:49:08.161824Z","shell.execute_reply":"2021-12-15T16:49:08.42039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}